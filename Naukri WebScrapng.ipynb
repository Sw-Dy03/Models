{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title> Machine Learning Jobs - Naukri.com </title>\n"
     ]
    }
   ],
   "source": [
    "base_url = 'http://www.naukri.com/machine-learning-jobs-'\n",
    "#page = requests.get(base_url)\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "req = urllib2.Request(base_url,headers=hdr)\n",
    "page = urllib2.urlopen(req)\n",
    "soup1 = BeautifulSoup(page,\"html5lib\")\n",
    "#Print the title\n",
    "print(soup1.title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description link: https://www.naukri.com/job-listings-Senior-Lead-Artificial-Intelligence-machine-Learning-CenturyLink-Technologies-India-Pvt-Ltd-Bengaluru-12-to-16-years-040918004955?src=nfl&sid=15361323208991&xp=1&px=1\n"
     ]
    }
   ],
   "source": [
    "all_links = [link.get('href') for link in soup1.findAll('a') if 'job-listings' in  str(link.get('href'))]\n",
    "print \"description link:\",all_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'https://www.naukri.com/job-listings-Senior-Lead-Artificial-Intelligence-machine-Learning-CenturyLink-Technologies-India-Pvt-Ltd-Bengaluru-12-to-16-years-040918004955?src=nfl&sid=15361323208991&xp=1&px=1'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title> Senior Lead - Artificial Intelligence/machine Learning - Bengaluru/Bangalore - CenturyLink Technologies India Pvt Ltd - 12 to 16 years of experience </title>\n"
     ]
    }
   ],
   "source": [
    "i_url=all_links[0]\n",
    "req = urllib2.Request(i_url,headers=hdr)\n",
    "page = urllib2.urlopen(req)\n",
    "soup = BeautifulSoup(page,\"html5lib\")\n",
    "#Print the title\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bengaluru\n"
     ]
    }
   ],
   "source": [
    "location = soup.find(\"div\",{\"class\":\"loc\"}).getText().strip()\n",
    "print location\n",
    "#for div in soup.find_all(class_='loc'):\n",
    "#    print div.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning, r, engine calibration, java, c++, ensemble modeling...\n",
      "Deep Learning, Natural Language Processing, Information Retrieval...\n",
      "Deep Learning, Computer Vision, Machine Learning, C++, Neural Networks...\n",
      "C, C++, Computer Vision, Opencv, MATLAB, Algorithms, Deep Learning, Python,...\n",
      "deep learning, r, machine learning, data science, regression analysis, time...\n",
      "Data Science, Oracle SQL, Machine Learning, Hadoop, Algorithms...\n",
      "c, computer vision, opencv, c++, matlab, deep learning, machine learning...\n",
      "Data Scientist, Machine Learning, C, C++, Java programming, Python, R...\n"
     ]
    }
   ],
   "source": [
    "# Key Skill\n",
    "for div in soup.find_all(class_='keySkills'):\n",
    "    print div.text\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-de8891a905e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Filter Key Skill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mkey_skills\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'|'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"ksTags\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'  '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mkey_skills\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "## Filter Key Skill\n",
    "key_skills = '|'.join(soup.find(\"div\",{\"class\":\"ksTags\"}).getText().split('  '))[1:]\n",
    "print key_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Salary': u'Not Disclosed by Recruiter', 'Functional Area': u'IT Software - Application Programming   ,     Maintenance', 'Industry': u'IT-Software  /    Software Services', 'Role Category': u'Programming & Design', 'Design Role': u'Team Lead/Technical Lead'}\n"
     ]
    }
   ],
   "source": [
    "# Role Level Information\n",
    "labels = ['Salary', 'Industry', 'Functional Area', 'Role Category', 'Design Role']\n",
    "role_info = [content.getText().split(':')[-1].strip() for content in soup.find(\"div\",{\"class\":\"jDisc mt20\"}).contents \n",
    " if len(str(content).replace(' ',''))!=0]\n",
    "\n",
    "role_info_dict = {label: role_info for label, role_info in zip(labels, role_info)}\n",
    "print role_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0fb47e5048d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompany_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"itemprop\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"hiringOrganization\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mcompany_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#jd_text = soup.find(\"ul\",{\"itemprop\":\"listing mt10 wb\"}).getText().strip()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print jd_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#jd_text = soup.find(\"ul\",{\"itemprop\":\"listing mt10 wb\"}).getText().strip()\n",
    "#print jd_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for div in soup1.find_all(class_='loc'):\n",
    "       #print(div.text)\n",
    "        Location=div.text \n",
    "# Experience Years\n",
    "for div in soup1.find_all(class_='exp'):\n",
    "        Experience=div.text\n",
    "        #print(div.text)       \n",
    "# Job Description\n",
    "for div in soup1.find_all(class_='desc'):\n",
    "        #print(div.text)\n",
    "        Job_Description =div.text\n",
    "# Job Skill\n",
    "for div in soup1.find_all(class_='skill'):\n",
    "        #print(div.text)\n",
    "        Skill=div.text\n",
    "# salary\n",
    "for div in soup1.find_all(class_='salary'):\n",
    "        #print(div.text)\n",
    "        Salary=div.text\n",
    "# desig\n",
    "for div in soup1.find_all(class_='desig'):\n",
    "        Designation=div.text\n",
    "        \n",
    "for div in soup1.find_all(class_='org'):\n",
    "        #print(div.text)\n",
    "        Organzation=div.text       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Skills',\n",
       "              u'|Deep Learning|| Machine Learning|| Data Mining|| NLP|| Data Science|| Computer Vision|| Artificial Intelligence|| Data Analysis|| Algorithms|| Analytics| '),\n",
       "             ('Experience', u'5-10 yrs'),\n",
       "             ('Job Description',\n",
       "              u'- Strong working experience of data mining techniques, including regression analysis, clustering, ...'),\n",
       "             ('Link',\n",
       "              u'https://www.naukri.com/job-listings-Senior-Lead-Artificial-Intelligence-machine-Learning-CenturyLink-Technologies-India-Pvt-Ltd-Bengaluru-12-to-16-years-040918004955?src=nfl&sid=15361323208991&xp=1&px=1'),\n",
       "             ('Location', u'Anywhere India'),\n",
       "             ('Organization', u'Rinalytics Advisors')])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "df_dict = OrderedDict({'Location':Location, 'Link':all_links[0],'Job Description':Job_Description,'Experience':Experience,\n",
    "                       'Skills':key_skills,'Organization':Organzation})\n",
    "#df_dict.update(role_info_dict)\n",
    "df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.Tech/B.E.\n",
      "[u'PG:M.Tech', u'-', u'Any', u'Specialization,', u'MCA', u'-', u'Computers']\n"
     ]
    }
   ],
   "source": [
    "# Education\n",
    "UG = soup.find(\"div\",{\"class\":\"jDisc mt10 edu\"}).getText().split()[1]\n",
    "print UG\n",
    "\n",
    "PG = soup.find(\"div\",{\"class\":\"jDisc mt10 edu\"}).getText().split()[5:]\n",
    "print PG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1-50 of 4857  Machine Learning Jobs  \n"
     ]
    }
   ],
   "source": [
    "#print soup.find(\"div\", { \"class\" : \"count\" }).h1.contents[1].getText()\n",
    "for div in soup.find_all(class_='count'):\n",
    "        print(div.text)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL of the last page to be scraped: http://www.naukri.com/machine-learning-jobs-98\n"
     ]
    }
   ],
   "source": [
    "num_jobs=4857\n",
    "num_pages = int(math.ceil(num_jobs/50.0))\n",
    "print \"URL of the last page to be scraped:\", base_url + str(num_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Together into one function\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from pandas import DataFrame\n",
    "from collections import OrderedDict\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<addinfourl at 190789128L whose fp = <socket._fileobject object at 0x000000000869ACF0>>\n",
      "<addinfourl at 197795016L whose fp = <socket._fileobject object at 0x000000000B757E58>>\n",
      "<addinfourl at 192233800L whose fp = <socket._fileobject object at 0x000000000BA208B8>>\n",
      "<addinfourl at 204990536L whose fp = <socket._fileobject object at 0x000000000A7F2408>>\n",
      "<addinfourl at 188942728L whose fp = <socket._fileobject object at 0x000000000BA20B10>>\n",
      "<addinfourl at 177955592L whose fp = <socket._fileobject object at 0x000000000BA209A8>>\n",
      "<addinfourl at 187872904L whose fp = <socket._fileobject object at 0x000000000B250840>>\n",
      "<addinfourl at 176247496L whose fp = <socket._fileobject object at 0x000000000869A9A8>>\n",
      "<addinfourl at 185118984L whose fp = <socket._fileobject object at 0x0000000008553D68>>\n",
      "<addinfourl at 188490888L whose fp = <socket._fileobject object at 0x000000000A31DCF0>>\n",
      "<addinfourl at 178341320L whose fp = <socket._fileobject object at 0x000000000B250930>>\n",
      "<addinfourl at 194985864L whose fp = <socket._fileobject object at 0x000000000B250048>>\n",
      "<addinfourl at 187098696L whose fp = <socket._fileobject object at 0x000000000B7579A8>>\n",
      "<addinfourl at 190681608L whose fp = <socket._fileobject object at 0x000000000BA204F8>>\n",
      "<addinfourl at 203129864L whose fp = <socket._fileobject object at 0x000000000A7F2750>>\n",
      "<addinfourl at 175252936L whose fp = <socket._fileobject object at 0x000000000A7F2228>>\n",
      "<addinfourl at 185121992L whose fp = <socket._fileobject object at 0x000000000BA200C0>>\n",
      "<addinfourl at 146937160L whose fp = <socket._fileobject object at 0x000000000BA20570>>\n",
      "<addinfourl at 198795080L whose fp = <socket._fileobject object at 0x000000000A31D8B8>>\n",
      "<addinfourl at 188001352L whose fp = <socket._fileobject object at 0x000000000B250E58>>\n",
      "<addinfourl at 184043848L whose fp = <socket._fileobject object at 0x000000000869AB10>>\n",
      "<addinfourl at 180438408L whose fp = <socket._fileobject object at 0x000000000869A6D8>>\n",
      "<addinfourl at 198425160L whose fp = <socket._fileobject object at 0x000000000BA20B10>>\n",
      "<addinfourl at 171397000L whose fp = <socket._fileobject object at 0x000000000869AA98>>\n",
      "<addinfourl at 189547528L whose fp = <socket._fileobject object at 0x000000000A31D390>>\n",
      "<addinfourl at 175252232L whose fp = <socket._fileobject object at 0x000000000B250B10>>\n",
      "<addinfourl at 184375240L whose fp = <socket._fileobject object at 0x000000000B250390>>\n",
      "<addinfourl at 204005704L whose fp = <socket._fileobject object at 0x000000000A9B7A98>>\n",
      "<addinfourl at 192425160L whose fp = <socket._fileobject object at 0x000000000A7F21B0>>\n",
      "<addinfourl at 181292808L whose fp = <socket._fileobject object at 0x0000000003CB7660>>\n",
      "<addinfourl at 186839368L whose fp = <socket._fileobject object at 0x000000000ACCBCF0>>\n",
      "<addinfourl at 183263624L whose fp = <socket._fileobject object at 0x000000000ACCBC00>>\n",
      "<addinfourl at 188585224L whose fp = <socket._fileobject object at 0x000000000A9B7408>>\n",
      "<addinfourl at 207109064L whose fp = <socket._fileobject object at 0x000000000B757A98>>\n",
      "<addinfourl at 189049800L whose fp = <socket._fileobject object at 0x000000000BA20A98>>\n",
      "<addinfourl at 181496200L whose fp = <socket._fileobject object at 0x000000000A7F24F8>>\n",
      "<addinfourl at 200856584L whose fp = <socket._fileobject object at 0x000000000869AE58>>\n",
      "<addinfourl at 184544456L whose fp = <socket._fileobject object at 0x000000000A31D7C8>>\n",
      "<addinfourl at 190936008L whose fp = <socket._fileobject object at 0x000000000BA20408>>\n",
      "<addinfourl at 188896968L whose fp = <socket._fileobject object at 0x000000000ACCBB10>>\n",
      "<addinfourl at 204853768L whose fp = <socket._fileobject object at 0x000000000B757138>>\n",
      "<addinfourl at 186257800L whose fp = <socket._fileobject object at 0x000000000A7F2F48>>\n",
      "<addinfourl at 207113544L whose fp = <socket._fileobject object at 0x000000000ACCB1B0>>\n",
      "<addinfourl at 199252360L whose fp = <socket._fileobject object at 0x000000000ACCBC78>>\n",
      "<addinfourl at 188622920L whose fp = <socket._fileobject object at 0x000000000B757390>>\n",
      "<addinfourl at 176178760L whose fp = <socket._fileobject object at 0x000000000A7F2ED0>>\n",
      "<addinfourl at 203070600L whose fp = <socket._fileobject object at 0x000000000A7F2138>>\n",
      "<addinfourl at 192726472L whose fp = <socket._fileobject object at 0x000000000B250318>>\n",
      "<addinfourl at 193543432L whose fp = <socket._fileobject object at 0x000000000B2506D8>>\n",
      "<addinfourl at 192711944L whose fp = <socket._fileobject object at 0x000000000A31D8B8>>\n",
      "<addinfourl at 191321672L whose fp = <socket._fileobject object at 0x000000000ACCBC78>>\n",
      "<addinfourl at 183645512L whose fp = <socket._fileobject object at 0x000000000B757570>>\n",
      "<addinfourl at 199457224L whose fp = <socket._fileobject object at 0x000000000B757A98>>\n",
      "<addinfourl at 181706056L whose fp = <socket._fileobject object at 0x0000000008553D68>>\n",
      "<addinfourl at 181580232L whose fp = <socket._fileobject object at 0x0000000008553DE0>>\n",
      "<addinfourl at 147460744L whose fp = <socket._fileobject object at 0x000000000A7F2B10>>\n",
      "<addinfourl at 178427592L whose fp = <socket._fileobject object at 0x000000000A7F2DE0>>\n",
      "<addinfourl at 188788360L whose fp = <socket._fileobject object at 0x000000000BA205E8>>\n",
      "<addinfourl at 178208328L whose fp = <socket._fileobject object at 0x000000000B757F48>>\n",
      "<addinfourl at 190164232L whose fp = <socket._fileobject object at 0x000000000B757C78>>\n",
      "<addinfourl at 204037896L whose fp = <socket._fileobject object at 0x0000000008C2E5E8>>\n",
      "<addinfourl at 191157832L whose fp = <socket._fileobject object at 0x000000000AA56840>>\n",
      "<addinfourl at 186276168L whose fp = <socket._fileobject object at 0x000000000A7F2480>>\n",
      "<addinfourl at 190973000L whose fp = <socket._fileobject object at 0x0000000008C2E5E8>>\n",
      "<addinfourl at 190926216L whose fp = <socket._fileobject object at 0x0000000008C2EB10>>\n",
      "<addinfourl at 188586312L whose fp = <socket._fileobject object at 0x000000000A7F26D8>>\n",
      "<addinfourl at 143046472L whose fp = <socket._fileobject object at 0x000000000AA56750>>\n",
      "<addinfourl at 176178312L whose fp = <socket._fileobject object at 0x000000000B757138>>\n",
      "<addinfourl at 179384520L whose fp = <socket._fileobject object at 0x000000000B757DE0>>\n",
      "<addinfourl at 190163080L whose fp = <socket._fileobject object at 0x000000000ACCBB10>>\n",
      "<addinfourl at 175348936L whose fp = <socket._fileobject object at 0x000000000A7F2DE0>>\n",
      "<addinfourl at 190936520L whose fp = <socket._fileobject object at 0x000000000A7F2D68>>\n",
      "<addinfourl at 146244808L whose fp = <socket._fileobject object at 0x000000000ACCB6D8>>\n",
      "<addinfourl at 191048712L whose fp = <socket._fileobject object at 0x000000000A7F2480>>\n",
      "<addinfourl at 199660808L whose fp = <socket._fileobject object at 0x000000000A7F2840>>\n",
      "<addinfourl at 180021256L whose fp = <socket._fileobject object at 0x000000000BA20C78>>\n",
      "<addinfourl at 198425160L whose fp = <socket._fileobject object at 0x000000000BA20840>>\n",
      "<addinfourl at 198666952L whose fp = <socket._fileobject object at 0x0000000008C2E570>>\n",
      "<addinfourl at 201937032L whose fp = <socket._fileobject object at 0x000000000B7575E8>>\n",
      "<addinfourl at 146901768L whose fp = <socket._fileobject object at 0x000000000B757B88>>\n",
      "<addinfourl at 188947464L whose fp = <socket._fileobject object at 0x000000000BA20ED0>>\n",
      "<addinfourl at 205883656L whose fp = <socket._fileobject object at 0x000000000BA20318>>\n",
      "<addinfourl at 195245896L whose fp = <socket._fileobject object at 0x000000000B7575E8>>\n",
      "<addinfourl at 200563208L whose fp = <socket._fileobject object at 0x000000000A7F2318>>\n",
      "<addinfourl at 181342472L whose fp = <socket._fileobject object at 0x000000000A7F2840>>\n",
      "<addinfourl at 192622280L whose fp = <socket._fileobject object at 0x0000000008C2E138>>\n",
      "<addinfourl at 198515528L whose fp = <socket._fileobject object at 0x000000000A31D8B8>>\n",
      "<addinfourl at 184360392L whose fp = <socket._fileobject object at 0x000000000A31D480>>\n",
      "<addinfourl at 177282376L whose fp = <socket._fileobject object at 0x000000000AA561B0>>\n",
      "<addinfourl at 145119368L whose fp = <socket._fileobject object at 0x000000000AA56840>>\n",
      "<addinfourl at 187168840L whose fp = <socket._fileobject object at 0x0000000008553DE0>>\n",
      "<addinfourl at 180605640L whose fp = <socket._fileobject object at 0x000000000A7F26D8>>\n",
      "<addinfourl at 200372808L whose fp = <socket._fileobject object at 0x0000000008C2E660>>\n",
      "<addinfourl at 176179208L whose fp = <socket._fileobject object at 0x0000000008C2E750>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<addinfourl at 180007944L whose fp = <socket._fileobject object at 0x000000000B250E58>>\n",
      "<addinfourl at 202928904L whose fp = <socket._fileobject object at 0x000000000AA56048>>\n",
      "<addinfourl at 199941064L whose fp = <socket._fileobject object at 0x000000000A31D570>>\n"
     ]
    }
   ],
   "source": [
    "base_url = 'http://www.naukri.com/machine-learning-jobs-'\n",
    "#page = requests.get(base_url)\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "d = {}\n",
    "\n",
    "num_jobs=4857\n",
    "num_pages = int(math.ceil(num_jobs/50.0))\n",
    "for page in range(1,num_pages):\n",
    "    page_url = base_url+str(page)\n",
    "    req = urllib2.Request(page_url,headers=hdr)\n",
    "    page = urllib2.urlopen(req)\n",
    "    soup1 = BeautifulSoup(page,\"html5lib\")\n",
    "    all_links = [link.get('href') for link in soup1.findAll('a') if 'job-listings' in  str(link.get('href'))]\n",
    "    for div in soup1.find_all(class_='loc'):\n",
    "        Location=div.text \n",
    "    # Experience Years\n",
    "    for div in soup1.find_all(class_='exp'):\n",
    "        Experience=div.text\n",
    "               \n",
    "    # Job Description\n",
    "    for div in soup1.find_all(class_='desc'):\n",
    "        Job_Description =div.text\n",
    "     # Job Skill\n",
    "    for div in soup1.find_all(class_='skill'):\n",
    "        Skill=div.text\n",
    "            # salary\n",
    "    for div in soup1.find_all(class_='salary'):\n",
    "        Salary=div.text\n",
    "    # desig\n",
    "    for div in soup1.find_all(class_='desig'):\n",
    "        Designation=div.text\n",
    "    #Organization\n",
    "    for div in soup1.find_all(class_='org'):\n",
    "        Organzation=div.text \n",
    "    for url in all_links:\n",
    "        reg1=req = urllib2.Request(url,headers=hdr)\n",
    "        page1 = urllib2.urlopen(reg1)\n",
    "        soup = BeautifulSoup(page1,\"html5lib\")\n",
    "        try:\n",
    "            labels = ['Salary', 'Industry', 'Functional Area', 'Role Category', 'Design Role']\n",
    "            role_info = [content.getText().split(':')[-1].strip() for content in soup.find(\"div\",{\"class\":\"jDisc mt20\"}).contents \n",
    "            if len(str(content).replace(' ',''))!=0]\n",
    "            role_info_dict = {label: role_info for label, role_info in zip(labels, role_info)}\n",
    "            #print role_info_dict\n",
    "            #key_skills = '|'.join(soup.find(\"div\",{\"class\":\"ksTags\"}).getText().split('  '))[1:]\n",
    "            d.setdefault('result', [])\n",
    "            \n",
    "            #df_dict.update(role_info_dict)\n",
    "            \n",
    "            #df_dict.append(role_info_dict)\n",
    "           # print df_dict\n",
    "            #naukri_df = naukri_df.append(df_dict,ignore_index=True)\n",
    "            #df_dict    \n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "    df_dict = OrderedDict({'Location':Location, 'Link':all_links[0],'Job Description':Job_Description,'Experience':Experience,\n",
    "                       'Skills':Skill,'Organization':Organzation})\n",
    "    df_dict.update(role_info_dict)\n",
    "    d.setdefault('result', [])\n",
    "    d['result'].append(df_dict)\n",
    "    \n",
    "    print page   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': [OrderedDict([('Skills',\n",
       "                u'Deep Learning, Natural Language Processing, Machine Learning...'),\n",
       "               ('Experience', u'4-8 yrs'),\n",
       "               ('Job Description',\n",
       "                u'- Experience with machine learning algorithms and data mining techniques;Experience in any of the below : ...'),\n",
       "               ('Link',\n",
       "                u'https://www.naukri.com/job-listings-Senior-Lead-Artificial-Intelligence-machine-Learning-CenturyLink-Technologies-India-Pvt-Ltd-Bengaluru-12-to-16-years-040918004955?src=nfl&sid=15361409335664&xp=1&px=1'),\n",
       "               ('Location', u'Chennai'),\n",
       "               ('Organization', u'eHelium'),\n",
       "               ('Salary', u'Not Disclosed by Recruiter'),\n",
       "               ('Functional Area',\n",
       "                u'IT Software - Application Programming   ,     Maintenance'),\n",
       "               ('Industry', u'Medical  /    Healthcare  /    Hospitals'),\n",
       "               ('Role Category', u'Programming & Design'),\n",
       "               ('Design Role', u'Technical Architect')]),\n",
       "  OrderedDict([('Skills',\n",
       "                u'Linear Regression, SAS SQL, R, Predictive Modeling, Logistic Regression...'),\n",
       "               ('Experience', u'10-12 yrs'),\n",
       "               ('Job Description',\n",
       "                u'Experience in leading delivery, client engagement management and deploying solutions;Excellent people ...'),\n",
       "               ('Link',\n",
       "                u'https://www.naukri.com/job-listings-NLP-Scientist-Data-Mining-machine-Learning-Rinalytics-Advisors-Anywhere-India-5-to-10-years-210818901182?src=jobsearchDesk&sid=15361409614990&xp=1&px=2'),\n",
       "               ('Location', u'Bengaluru'),\n",
       "               ('Organization', u'Citicorp Services India Pvt Ltd'),\n",
       "               ('Salary', u'Not Disclosed by Recruiter'),\n",
       "               ('Functional Area',\n",
       "                u'IT Software - Application Programming   ,     Maintenance'),\n",
       "               ('Industry', u'IT-Software  /    Software Services'),\n",
       "               ('Role Category', u'Programming & Design'),\n",
       "               ('Design Role', u'Team Lead/Technical Lead')])]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
